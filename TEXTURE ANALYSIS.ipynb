{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from csv import reader\n",
    "import copy \n",
    "import cv2\n",
    "from mpl_toolkits import mplot3d\n",
    "import argparse\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(directory):\n",
    "    ''' Set outliers to threshold value in csv-format data from SPIM-FRAP'd cell nuclei. In the original use of this\n",
    "    code, an outlier-riddled file named '0CRECO_200731.csv' was converted to a clean file called 'C0R.csv'. '''\n",
    "    \n",
    "    objlist = []\n",
    "    for filename in os.listdir(directory + '/unclean data'):\n",
    "        if filename.endswith(\".csv\"):\n",
    "\n",
    "            cellnum = filename[1] \n",
    "            compstate = filename[0]\n",
    "            datatype = filename[2]\n",
    "            objname = compstate + cellnum + datatype\n",
    "            objlist.append(objname)\n",
    "            \n",
    "            \n",
    "            # Convert to numpy array so values can be modified and analyzed\n",
    "            a = np.array(pd.read_csv(directory + '/unclean data' + '/{}'.format(filename))) \n",
    "            a0 = copy.deepcopy(a) \n",
    "            \n",
    "            # Accumulate individual nucleus data points in a list\n",
    "            vallist = [] \n",
    "            vallist.append(a[a != 0.0])\n",
    "            \n",
    "            # Establish outlier qualifications\n",
    "            Q1 = np.percentile(vallist, 25)\n",
    "            Q2 = np.percentile(vallist, 50)\n",
    "            Q3 = np.percentile(vallist, 75)\n",
    "            UPPERTHRESH = Q3 + ((Q3-Q1)*1.5)\n",
    "            if (datatype == 'r') and (UPPERTHRESH > 1.0):       # recovery percent values should be less than 1.0\n",
    "                UPPERTHRESH = 1.0\n",
    "            LOWERTHRESH = Q1 - ((Q3-Q1)*1.5)\n",
    "            if LOWERTHRESH < 0.0:                               # no values should be negative\n",
    "                LOWERTHRESH = 0.0\n",
    "            \n",
    "            # Set outliers to the threshold value\n",
    "            a[a > UPPERTHRESH] = UPPERTHRESH\n",
    "            a[(a < LOWERTHRESH) & (a != 0.0)] = LOWERTHRESH\n",
    "\n",
    "            # Verify whether any outliers exist and if they ever existed\n",
    "            if np.any(a > UPPERTHRESH):                                 \n",
    "                print('ERROR: high outliers remain in', filename, 'threshold: ', Q3)\n",
    "            if np.any((a != 0.0) & (a < LOWERTHRESH)):\n",
    "                print('ERROR: low outliers remain in', filename, 'threshold: ', Q1)\n",
    "            elif np.any(a - a0 != 0) == True:                                   \n",
    "                print(filename, ' has been cleaned up')\n",
    "                pd.DataFrame(a).to_csv(directory + '/cleaned data' + \n",
    "                                       '/{}'.format(objname) + '.csv', header=None, index=None) \n",
    "            else:\n",
    "                print(filename, ' had no outliers')\n",
    "                pd.DataFrame(a).to_csv(directory + '/cleaned data' + \n",
    "                                       '/{}'.format(objname) + '.csv', header=None, index=None)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOBEL(cs, cn, dt, kernel, orientation):\n",
    "    ''' Visualize the approximation of the gradient value at each location in the cell nucleus. This should indicate \n",
    "    the extent to which neighboring recovery percentage or recovery time values are changing at each point, and give a\n",
    "    measure of texture in the image. Orientation 'X' will allow you to see your kernel convolved horizontally, orientation\n",
    "    'Y' will show the vertical convolution results, and orientation 'XY' combines these images and is what I have found \n",
    "    most useful to work with. Your designated kernel size will allow you to choose how many neighboring pixels to\n",
    "    incorporate into this measurement, and must be an odd integer. A larger value for this may be less useful in\n",
    "    considering small cells, as you may amplify the contributions of the nuclear boundary (where there is the most\n",
    "    sudden increase or decrease in intensity) throughout the file. This is an existing function, part of the CV2 library. '''\n",
    "    \n",
    "    b = np.array(pd.read_csv(directory + '/cleaned data/' + cs + cn + dt + '.csv'))\n",
    "    matrixX = cv2.Sobel(b, cv2.CV_64F, 1, 0, ksize=kernel)\n",
    "    matrixY = cv2.Sobel(b, cv2.CV_64F, 0, 1, ksize=kernel)\n",
    "    matrixXY = np.sqrt((matrixX**2) + (matrixY**2))\n",
    "    \n",
    "    if orientation == \"X\":\n",
    "        return matrixX\n",
    "    if orientation == \"Y\":\n",
    "        return matrixY\n",
    "    if orientation == \"XY\":\n",
    "        pd.DataFrame(matrixXY).to_csv(directory + '/sobel/' + cs + cn + dt + '.csv', header=None, index=None)\n",
    "        return matrixXY\n",
    "    \n",
    "    plt.subplot(2,2,1),plt.imshow(b, cmap = 'gray')\n",
    "    plt.title('Original File'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(2,2,2),plt.imshow(matrixXY, cmap = 'gray')\n",
    "    plt.title('Combined Sobel'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(2,2,3),plt.imshow(matrixX,cmap = 'gray')\n",
    "    plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(2,2,4),plt.imshow(matrixY,cmap = 'gray')\n",
    "    plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eatEdge(compstate, cellnum, datatype, directory):\n",
    "    ''' Eat away the top and bottom edge of a sobel-processed SPIM-FRAP'd cell image so that texture values \n",
    "    included do not represent the boundary of the cell. In the original use of this code function, COMPSTATE = 'u' or 'c',\n",
    "    CELLNUM is an integer referring to a cell in the data set (0-6), and DATATYPE = 'r' or 't'. It is very important that\n",
    "    you visualize the results of this process, which can be a little less reliable when employing larger values for\n",
    "    the kernel size of the sobel operator. If needed, the manualCorrection factor can be used to adjust the final\n",
    "    iteration count as you see fit. '''\n",
    "    \n",
    "    \n",
    "    # Load file into matrix, set labelled indices to 0.0\n",
    "    s = np.array(pd.read_csv(directory + '/sobel/' + compstate + cellnum + datatype + '.csv')) \n",
    "    s[0,:] = 0.0\n",
    "    s[:,0] = 0.0\n",
    "    \n",
    "    s0 = copy.deepcopy(s)   # create copy to compare result against\n",
    "    t = copy.deepcopy(s)    # create copy to eat once appropriate iteration value is established\n",
    "    \n",
    "    \n",
    "    # Instantiate lists\n",
    "    sumList = [np.sum(s)]   # contain sum values for each eating trial \n",
    "    tumList = [np.sum(t)]\n",
    "    ratioList = []          # compare one value in sumList to the previous\n",
    "    tRatioList = []\n",
    "    \n",
    "    \n",
    "    # Establish appropriate number of times to eat edges\n",
    "    for iter in range(20):                              # try eating the edges 20 times\n",
    "        for i in range(1, s.shape[1]):                  \n",
    "            if np.any(s[:,i] != 0.0):                   \n",
    "                jmin = np.min(np.where(s[:,i] > 0.0))   # find top edge\n",
    "                jmax = np.max(np.where(s[:,i] > 0.0))   # find bottom edge\n",
    "                s[jmin,i] = 0.0                         # EAT TOP EDGE\n",
    "                s[jmax,i] = 0.0                         # EAT BOTTOM EDGE\n",
    "        sumList.append(np.sum(s))                       # record the sum of all values in current matrix\n",
    "        ratioList.append(sumList[-1]/sumList[-2])\n",
    "    \n",
    "    \n",
    "    # Find how many trials it took to achieve the least significant decrease\n",
    "    eatTrials = np.argmax(ratioList[3:])                # only measurements made after >=3 iterations are viable\n",
    "    print('eatTrials = ', eatTrials)\n",
    "    \n",
    "    manualCorrection = 0                                # increase or decrease number if you suspect that more or less iterations are needed\n",
    "    print('manualCorrection = ', manualCorrection)\n",
    "    \n",
    "    # Repeat the eating sequence on copied matrix appropriately\n",
    "    for iter in range(eatTrials + 2 + manualCorrection):                  \n",
    "        for i in range(1, t.shape[1]):                  \n",
    "            if np.any(t[:,i] != 0.0):                   \n",
    "                jmin = np.min(np.where(t[:,i] > 0.0))  \n",
    "                jmax = np.max(np.where(t[:,i] > 0.0)) \n",
    "                t[jmin,i] = 0.0                           \n",
    "                t[jmax,i] = 0.0\n",
    "        tumList.append(np.sum(t))\n",
    "        tRatioList.append(tumList[-1]/tumList[-2])\n",
    "    \n",
    "    \n",
    "    # Save the new, edgeless file\n",
    "    pd.DataFrame(t).to_csv(directory + '/sobel no edge/' + compstate + cellnum + datatype + '.csv',\n",
    "                              header=None, index=None)        \n",
    "\n",
    "    # See if the results look reasonable\n",
    "    plt.subplot(2,2,1), plt.imshow(s0, cmap = 'gray')\n",
    "    plt.title('original file')\n",
    "    plt.subplot(2,2,2), plt.imshow(t, cmap = 'gray')\n",
    "    plt.title('edgeless file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indentionIdentifier(cellnum, datatype, directory, step):\n",
    "    ''' Identify the region of a cell nucleus that has been compressed by an AFM cantilever. Function returns\n",
    "    two indices, representing the columns that you should limit your examinations to when studying the compressed\n",
    "    region or the outside region. You can control how narrow this region is by specifying the 'step', which should\n",
    "    be on the order of 10 pixels, and allows you to step inward (wilth positive number) or outward (with negaitive value)\n",
    "    from each of the bumps that are identified as the points where the compressed cell is tallest. '''\n",
    "    \n",
    "    \n",
    "    # Load the confined and not confined data for the same cell nucleus\n",
    "    c = np.array(pd.read_csv(directory + '/sobel no edge/' + 'c' + cellnum + datatype + '.csv')) \n",
    "    u = np.array(pd.read_csv(directory + '/sobel no edge/' + 'u' + cellnum + datatype + '.csv'))\n",
    "    \n",
    "    \n",
    "    # Find the length column that contains data for the nucleus\n",
    "    vertLength = []            # length of vertical strips for compressed cell\n",
    "    uLength = []               # length of vertical strips for noncompressed cell\n",
    "    columns = []               # associated column indices\n",
    "    \n",
    "    \n",
    "    for i in range(1, c.shape[1]):                     # look at each column\n",
    "        columns.append(i)                              # record column index\n",
    "        \n",
    "        if np.any( c[:, i] != 0.0 ):\n",
    "            j0 = np.min(np.where( c[:,i] > 0.0 ))\n",
    "            jf = np.max(np.where( c[:,i] > 0.0 ))\n",
    "            vL = jf - j0                               # record length of column in compressed cell data\n",
    "            vertLength.append(vL)\n",
    "        if np.all( c[:, i] == 0.0 ):\n",
    "            vertLength.append(0.0)\n",
    "                \n",
    "            \n",
    "        if np.any( u[:, i] != 0.0 ):\n",
    "            uj0 = np.min(np.where( u[:,i] > 0.0 ))\n",
    "            ujf = np.max(np.where( u[:,i] > 0.0 ))\n",
    "            uvL = ujf - uj0                            # record length of column from non-compressed cell data\n",
    "            uLength.append(uvL)\n",
    "        if np.all( u[:,i] == 0.0 ):\n",
    "            uLength.append(0.0)\n",
    "            \n",
    "            \n",
    "    # Examine the change in the height of the cell nucleus to place bump indices\n",
    "    dVL = np.diff(vertLength)\n",
    "    mp = int(0.5*(columns[0] + columns[-1]))\n",
    "    \n",
    "    rightBump = 0\n",
    "    for n in range(1, mp):\n",
    "        rightBump = np.max(np.where(dVL > 0.0))\n",
    "    leftBump = 0\n",
    "    for m in range(mp, len(columns)-2):\n",
    "        leftBump = np.min(np.where(dVL < 0.0))\n",
    "        \n",
    "        \n",
    "    # Uncomment the following code to compare the lengths of the data-populated regions in each column amond files (u vs. c)\n",
    "    #for i in range(len(vertLength)):\n",
    "    #    print(str(vertLength[i+1]) + '\\t' +  str(dVL[i]) + '\\t' + str(uLength[i+1]) + '\\t' + str(columns[i]))\n",
    "    \n",
    "    return [leftBump + step, rightBump - step]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGet(cellnum, datatype, directory, step, Type):\n",
    "    ''' Compare the Median or the Mean of either the compressed regions or the outer regions between data for a \n",
    "    cell measured in and before confinement. Visualize the region from which you are measuring a value, so that\n",
    "    you can adjust your step size if necessary. '''\n",
    "    \n",
    "    c = np.array(pd.read_csv(direct + '/sobel no edge/' + 'c' + cellnum + datatype + '.csv')) \n",
    "    u = np.array(pd.read_csv(direct + '/sobel no edge/' + 'u' + cellnum + datatype + '.csv'))\n",
    "    c0 = copy.deepcopy(c)\n",
    "    u0 = copy.deepcopy(u)\n",
    "    \n",
    "    [L,R] = indentionIdentifier(cellnum, datatype, directory, step)\n",
    "    \n",
    "    noncData = 0.0\n",
    "    compData = 0.0\n",
    "    \n",
    "    if Type == 'InnerMean':\n",
    "        u0[:,:(L-1)] = 0.0\n",
    "        u0[:,(R+1):] = 0.0\n",
    "        c0[:,:(L-1)] = 0.0\n",
    "        c0[:,(R+1):] = 0.0\n",
    "        noncData = np.average(np.nonzero(u0))\n",
    "        compData = np.average(np.nonzero(c0))\n",
    "    \n",
    "    if Type == 'OuterMean':\n",
    "        u0[:,L:R] = 0.0\n",
    "        c0[:,L:R] = 0.0\n",
    "        noncData = np.average(np.nonzero(u0))\n",
    "        compData = np.average(np.nonzero(c0))\n",
    "        \n",
    "    if Type == 'InnerMedian':\n",
    "        u0[:,:(L-1)] = 0.0\n",
    "        u0[:,(R+1):] = 0.0\n",
    "        c0[:,:(L-1)] = 0.0\n",
    "        c0[:,(R+1):] = 0.0\n",
    "        noncData = np.median(np.nonzero(u0))\n",
    "        compData = np.median(np.nonzero(c0))\n",
    "        \n",
    "    if Type == 'OuterMedian':\n",
    "        u0[:,L:R] = 0.0\n",
    "        c0[:,L:R] = 0.0\n",
    "        noncData = np.median(np.nonzero(u0))\n",
    "        compData = np.median(np.nonzero(c0))\n",
    "\n",
    "        \n",
    "    plt.subplot(2,2,1),plt.imshow(u,cmap='gray')\n",
    "    plt.title('non-compressed cell '+ cellnum)\n",
    "    plt.subplot(2,2,2),plt.imshow(c,cmap='gray')\n",
    "    plt.title('compressed cell '+ cellnum)\n",
    "    plt.subplot(2,2,3),plt.imshow(u0,cmap='gray')\n",
    "    plt.title(str(noncData))\n",
    "    plt.subplot(2,2,4),plt.imshow(c0,cmap='gray')\n",
    "    plt.title(str(compData))\n",
    "        \n",
    "    return noncData, compData\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
